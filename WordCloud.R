library(stringr) 
library(dplyr) 
library(tidytext) 
library(stopwords) 
library(tibble) 
library(ggplot2) 
library(wordcloud)
library(readr)
library(tidyverse)
library(wordcloud2) # import necessary libraries
setwd("/Users/<>/Desktop/Research") # change as necessary
dat=read_csv("USAirlinesTweets.csv")
neu_dat=dat %>% filter(sentiment=="neutral")
pos_dat=dat %>% filter(sentiment=="positive")
neg_dat=dat %>% filter(sentiment=="negative")
dat=dat %>% select(tweet)
neu_dat=neu_dat %>% select(tweet)
pos_dat=pos_dat %>% select(tweet)
neg_dat=neg_dat %>% select(tweet)
drop_na(dat)
drop_na(neu_dat)
drop_na(pos_dat)
drop_na(neg_dat)
tidy_dat <- dat %>% tidytext::unnest_tokens(word, tweet) %>% group_by(word) %>% filter(n() > 10) %>% ungroup()
neu_tidy_dat <- neu_dat %>% tidytext::unnest_tokens(word, tweet) %>% group_by(word) %>% filter(n() > 10) %>% ungroup()
pos_tidy_dat <- pos_dat %>% tidytext::unnest_tokens(word, tweet) %>% group_by(word) %>% filter(n() > 10) %>% ungroup()
neg_tidy_dat <- neg_dat %>% tidytext::unnest_tokens(word, tweet) %>% group_by(word) %>% filter(n() > 10) %>% ungroup()
stopword <- as_tibble(stopwords::stopwords("en"))
stopword <- rename(stopword,word=value)
additional <- tibble(
  word = c("t.co", "http","2","amp","3","4","w")
) # adding additional stopwords
stopword <- full_join(stopword, additional);
td <- anti_join(tidy_dat,stopword,by="word")
neu_td <- anti_join(neu_tidy_dat,stopword,by="word")
pos_td <- anti_join(pos_tidy_dat,stopword,by="word")
neg_td <- anti_join(neg_tidy_dat,stopword,by="word")
word_count <- count(td,word,sort=TRUE)
print(word_count,n=100) 
td %>%count(word)%>%with(wordcloud(word, n, max.words=100, colors=brewer.pal(8, "Dark2"))) #brewer.pal(n,name) = color palette, n=# of colors, name=c("Accent", "Dark2", "Paired" #"Pastel1", "Pastel2", "Set1", "Set2", "Set3")
# makes word cloud
