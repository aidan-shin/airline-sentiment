{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RM48rHodbW3I",
        "outputId": "f236c2de-5081-4095-bd4e-999d71b0e2fa"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "/tmp/ipython-input-830504261.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  df=df[df['sentiment']=='negative'][df['negativereason']!=\"Can't Tell\"] # filtering dataframe\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3010' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3010/3495 2:02:07 < 19:41, 0.41 it/s, Epoch 4.30/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.922700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.852700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.740400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.710000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3495' max='3495' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3495/3495 2:21:50, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.073400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.922700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.852700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.740400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.710000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.032793641090393, 'eval_accuracy': 0.6896120150187734, 'eval_f1_weighted': 0.6754757305107031, 'eval_precision_weighted': 0.6646066836033765, 'eval_recall_weighted': 0.6896120150187734, 'eval_precision_class_0': 0.48717948717948717, 'eval_recall_class_0': 0.40425531914893614, 'eval_f1_class_0': 0.4418604651162791, 'eval_support_class_0': 141.0, 'eval_precision_class_1': 0.5094339622641509, 'eval_recall_class_1': 0.5192307692307693, 'eval_f1_class_1': 0.5142857142857142, 'eval_support_class_1': 156.0, 'eval_precision_class_2': 0.7330595482546202, 'eval_recall_class_2': 0.796875, 'eval_f1_class_2': 0.7636363636363637, 'eval_support_class_2': 896.0, 'eval_precision_class_3': 0.7149122807017544, 'eval_recall_class_3': 0.7309417040358744, 'eval_f1_class_3': 0.7228381374722838, 'eval_support_class_3': 223.0, 'eval_precision_class_4': 0.6962699822380106, 'eval_recall_class_4': 0.7701375245579568, 'eval_f1_class_4': 0.7313432835820896, 'eval_support_class_4': 509.0, 'eval_precision_class_5': 0.0, 'eval_recall_class_5': 0.0, 'eval_f1_class_5': 0.0, 'eval_support_class_5': 20.0, 'eval_precision_class_6': 0.7833333333333333, 'eval_recall_class_6': 0.7372549019607844, 'eval_f1_class_6': 0.7595959595959596, 'eval_support_class_6': 255.0, 'eval_precision_class_7': 0.0, 'eval_recall_class_7': 0.0, 'eval_f1_class_7': 0.0, 'eval_support_class_7': 48.0, 'eval_precision_class_8': 0.5, 'eval_recall_class_8': 0.38926174496644295, 'eval_f1_class_8': 0.4377358490566038, 'eval_support_class_8': 149.0, 'eval_runtime': 202.054, 'eval_samples_per_second': 11.863, 'eval_steps_per_second': 1.485, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.75      0.73       340\n",
            "           1       0.77      0.79      0.78       424\n",
            "           2       0.88      0.91      0.89      2014\n",
            "           3       0.84      0.88      0.86       501\n",
            "           4       0.84      0.92      0.87      1156\n",
            "           5       0.00      0.00      0.00        54\n",
            "           6       0.86      0.82      0.84       592\n",
            "           7       1.00      0.04      0.07       130\n",
            "           8       0.76      0.71      0.73       380\n",
            "\n",
            "    accuracy                           0.84      5591\n",
            "   macro avg       0.74      0.65      0.64      5591\n",
            "weighted avg       0.83      0.84      0.82      5591\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.40      0.44       141\n",
            "           1       0.51      0.52      0.51       156\n",
            "           2       0.73      0.80      0.76       896\n",
            "           3       0.71      0.73      0.72       223\n",
            "           4       0.70      0.77      0.73       509\n",
            "           5       0.00      0.00      0.00        20\n",
            "           6       0.78      0.74      0.76       255\n",
            "           7       0.00      0.00      0.00        48\n",
            "           8       0.50      0.39      0.44       149\n",
            "\n",
            "    accuracy                           0.69      2397\n",
            "   macro avg       0.49      0.48      0.49      2397\n",
            "weighted avg       0.66      0.69      0.68      2397\n",
            "\n",
            "['The airport lost my bags, would not recommend.', \"The customer service was horrendous and didn't listen to me, I demand my money back!\", \"I wanted to book some seats all in a row for my family, but the website wouldn't let me even though they all showed as available.\", 'Why is there still only one terminal for this section? I have to wait forever to get to my flight.', 'I had instruments in my luggage, but they were all damaged when I got them back. I demand to be compensated for this!', 'The flight attendants were very rude to me and refused to serve me snacks.']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PredictionOutput(predictions=array([[-0.39649984, -1.2392728 , -0.41867024,  3.775128  , -0.76235855,\n",
            "         0.15429991, -0.30775326, -0.35913384, -0.87179023],\n",
            "       [-0.31218076, -1.1314658 ,  4.722972  , -0.698938  , -0.57097685,\n",
            "        -1.643983  , -0.60682726, -0.701203  , -0.11647189],\n",
            "       [-0.48680884,  0.46946236,  1.3060435 , -0.8938089 , -0.77265763,\n",
            "        -1.490014  , -0.18414132, -0.9677125 ,  1.9347365 ],\n",
            "       [-0.519021  , -0.6651811 ,  0.60306764, -0.6721138 ,  1.7523743 ,\n",
            "        -1.4529951 ,  0.8087218 , -0.03857224, -0.86727756],\n",
            "       [-0.1449628 , -0.59634924,  0.09826794,  2.5973651 , -0.4798279 ,\n",
            "        -0.07439104, -0.61499524, -0.52286494, -0.69575477],\n",
            "       [ 2.6968806 ,  0.01893388,  0.84494245, -0.8049284 , -0.519119  ,\n",
            "        -1.1598305 , -0.90577173, -0.16752988, -1.1670196 ]],\n",
            "      dtype=float32), label_ids=array([1, 1, 1, 1, 1, 1]), metrics={'test_loss': 3.8463058471679688, 'test_accuracy': 0.0, 'test_f1_weighted': 0.0, 'test_precision_weighted': 0.0, 'test_recall_weighted': 0.0, 'test_precision_class_0': 0.0, 'test_recall_class_0': 0.0, 'test_f1_class_0': 0.0, 'test_support_class_0': 0.0, 'test_precision_class_1': 0.0, 'test_recall_class_1': 0.0, 'test_f1_class_1': 0.0, 'test_support_class_1': 6.0, 'test_precision_class_2': 0.0, 'test_recall_class_2': 0.0, 'test_f1_class_2': 0.0, 'test_support_class_2': 0.0, 'test_precision_class_3': 0.0, 'test_recall_class_3': 0.0, 'test_f1_class_3': 0.0, 'test_support_class_3': 0.0, 'test_precision_class_4': 0.0, 'test_recall_class_4': 0.0, 'test_f1_class_4': 0.0, 'test_support_class_4': 0.0, 'test_precision_class_5': 0.0, 'test_recall_class_5': 0.0, 'test_f1_class_5': 0.0, 'test_support_class_5': 0.0, 'test_precision_class_6': 0.0, 'test_recall_class_6': 0.0, 'test_f1_class_6': 0.0, 'test_support_class_6': 0.0, 'test_precision_class_7': 0.0, 'test_recall_class_7': 0.0, 'test_f1_class_7': 0.0, 'test_support_class_7': 0.0, 'test_precision_class_8': 0.0, 'test_recall_class_8': 0.0, 'test_f1_class_8': 0.0, 'test_support_class_8': 0.0, 'test_runtime': 0.3698, 'test_samples_per_second': 16.225, 'test_steps_per_second': 2.704})\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=9)\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "# remove stopwords\n",
        "\n",
        "df = pd.read_csv('USAirlinesTweets.csv', encoding='latin1')\n",
        "df=df[df['sentiment']=='negative'][df['negativereason']!=\"Can't Tell\"] # filtering dataframe\n",
        "label_mapping = {\"Flight Attendant Complaints\": 0, \"Bad Flight\": 1, \"Customer Service Issue\": 2, 'Lost Luggage': 3, 'Late Flight': 4, 'Damaged Luggage': 5, 'Cancelled Flight': 6, 'longlines': 7, 'Flight Booking Problems': 8}\n",
        "news_quality = df['negativereason'].map(label_mapping)\n",
        "news_text = df['tweet'].tolist()\n",
        "x=[]\n",
        "words=stopwords.words(\"english\")\n",
        "words+=['@','!','.',',','?','#']\n",
        "for i in news_text:\n",
        "  tweet=i\n",
        "  tweet=word_tokenize(tweet.lower())\n",
        "  tweet=[j for j in tweet if j not in words]\n",
        "  y=' '.join(tweet)\n",
        "  for i in ['@','!','.',',','?','#']:\n",
        "    y=y.replace(i,'')\n",
        "  x.append(y)\n",
        "news_text=x\n",
        "\n",
        "\n",
        "train_news_text, test_news_text, train_news_quality, test_news_quality = train_test_split(\n",
        "    news_text, news_quality, test_size=0.3, random_state=42)\n",
        "\n",
        "encodings = tokenizer(train_news_text, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "encodings_test = tokenizer(test_news_text, truncation = True, padding=True, return_tensors = \"pt\")\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "train_dataset = CustomDataset(encodings, torch.tensor(train_news_quality.values))\n",
        "test_dataset = CustomDataset(encodings_test, torch.tensor(test_news_quality.values))\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
        "    predictions = np.argmax(probs, axis=1)  # pick class with highest probability\n",
        "\n",
        "    report = classification_report(labels, predictions, output_dict=True)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_weighted\": report[\"weighted avg\"][\"f1-score\"],\n",
        "        \"precision_weighted\": report[\"weighted avg\"][\"precision\"],\n",
        "        \"recall_weighted\": report[\"weighted avg\"][\"recall\"]\n",
        "    }\n",
        "    for class_label in [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]:\n",
        "        if class_label in report: # Check if class label exists in the report\n",
        "            metrics[f\"precision_class_{class_label}\"] = report[class_label][\"precision\"]\n",
        "            metrics[f\"recall_class_{class_label}\"] = report[class_label][\"recall\"]\n",
        "            metrics[f\"f1_class_{class_label}\"] = report[class_label][\"f1-score\"]\n",
        "            metrics[f\"support_class_{class_label}\"] = report[class_label][\"support\"]\n",
        "        else: # If class label doesn't exist, set metrics to 0\n",
        "            metrics[f\"precision_class_{class_label}\"] = 0.0\n",
        "            metrics[f\"recall_class_{class_label}\"] = 0.0\n",
        "            metrics[f\"f1_class_{class_label}\"] = 0.0\n",
        "            metrics[f\"support_class_{class_label}\"] = 0.0\n",
        "    return metrics\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=1e-5\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics)\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "results = trainer.evaluate()\n",
        "\n",
        "print(results)\n",
        "preds = trainer.predict(train_dataset)\n",
        "preds = np.argmax(preds[:3][0],axis=1)\n",
        "GT = train_news_quality\n",
        "print(classification_report(GT,preds))\n",
        "preds = trainer.predict(test_dataset)\n",
        "preds = np.argmax(preds[:3][0],axis=1)\n",
        "GT = test_news_quality\n",
        "print(classification_report(GT,preds))\n",
        "\n",
        "sentences=['The airport lost my bags, would not recommend.', \\\n",
        "           'The customer service was horrendous and didn\\'t listen to me, I demand my money back!', \\\n",
        "           'I wanted to book some seats all in a row for my family, but the website wouldn\\'t let me even though they all showed as available.', \\\n",
        "           \"Why is there still only one terminal for this section? I have to wait forever to get to my flight.\", \\\n",
        "           \"I had instruments in my luggage, but they were all damaged when I got them back. I demand to be compensated for this!\", \\\n",
        "           \"The flight attendants were very rude to me and refused to serve me snacks.\", \\\n",
        "           ]\n",
        "print(sentences)\n",
        "x=CustomDataset(tokenizer(sentences, truncation=True, padding=True, return_tensors=\"pt\"), torch.tensor(np.array([1]*len(sentences))))\n",
        "preds2 = trainer.predict(x)\n",
        "print(preds2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vz0juOzmbX-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
